{"ast":null,"code":"import { syntaxError } from '../error/syntaxError.mjs';\nimport { Token } from './ast.mjs';\nimport { isNameStart } from './characterClasses.mjs';\nimport { createToken, printCodePointAt, readName } from './lexer.mjs';\nimport { TokenKind } from './tokenKind.mjs';\n/**\n * Given a Source schema coordinate, creates a Lexer for that source.\n * A SchemaCoordinateLexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\n\nexport class SchemaCoordinateLexer {\n  /**\n   * The previously focused non-ignored token.\n   */\n\n  /**\n   * The currently focused non-ignored token.\n   */\n\n  /**\n   * The (1-indexed) line containing the current token.\n   * Since a schema coordinate may not contain newline, this value is always 1.\n   */\n  line = 1;\n  /**\n   * The character offset at which the current line begins.\n   * Since a schema coordinate may not contain newline, this value is always 0.\n   */\n\n  lineStart = 0;\n  constructor(source) {\n    const startOfFileToken = new Token(TokenKind.SOF, 0, 0, 0, 0);\n    this.source = source;\n    this.lastToken = startOfFileToken;\n    this.token = startOfFileToken;\n  }\n  get [Symbol.toStringTag]() {\n    return 'SchemaCoordinateLexer';\n  }\n  /**\n   * Advances the token stream to the next non-ignored token.\n   */\n\n  advance() {\n    this.lastToken = this.token;\n    const token = this.token = this.lookahead();\n    return token;\n  }\n  /**\n   * Looks ahead and returns the next non-ignored token, but does not change\n   * the current Lexer token.\n   */\n\n  lookahead() {\n    let token = this.token;\n    if (token.kind !== TokenKind.EOF) {\n      // Read the next token and form a link in the token linked-list.\n      const nextToken = readNextToken(this, token.end); // @ts-expect-error next is only mutable during parsing.\n\n      token.next = nextToken; // @ts-expect-error prev is only mutable during parsing.\n\n      nextToken.prev = token;\n      token = nextToken;\n    }\n    return token;\n  }\n}\n/**\n * Gets the next token from the source starting at the given position.\n */\n\nfunction readNextToken(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  const position = start;\n  if (position < bodyLength) {\n    const code = body.charCodeAt(position);\n    switch (code) {\n      case 0x002e:\n        // .\n        return createToken(lexer, TokenKind.DOT, position, position + 1);\n      case 0x0028:\n        // (\n        return createToken(lexer, TokenKind.PAREN_L, position, position + 1);\n      case 0x0029:\n        // )\n        return createToken(lexer, TokenKind.PAREN_R, position, position + 1);\n      case 0x003a:\n        // :\n        return createToken(lexer, TokenKind.COLON, position, position + 1);\n      case 0x0040:\n        // @\n        return createToken(lexer, TokenKind.AT, position, position + 1);\n    } // Name\n\n    if (isNameStart(code)) {\n      return readName(lexer, position);\n    }\n    throw syntaxError(lexer.source, position, `Invalid character: ${printCodePointAt(lexer, position)}.`);\n  }\n  return createToken(lexer, TokenKind.EOF, bodyLength, bodyLength);\n}","map":{"version":3,"names":["syntaxError","Token","isNameStart","createToken","printCodePointAt","readName","TokenKind","SchemaCoordinateLexer","line","lineStart","constructor","source","startOfFileToken","SOF","lastToken","token","Symbol","toStringTag","advance","lookahead","kind","EOF","nextToken","readNextToken","end","next","prev","lexer","start","body","bodyLength","length","position","code","charCodeAt","DOT","PAREN_L","PAREN_R","COLON","AT"],"sources":["C:/Users/porta/OneDrive/Documentos/Univalle/MercaDEA/Panel-Amin-Nuevo/node_modules/graphql/language/schemaCoordinateLexer.mjs"],"sourcesContent":["import { syntaxError } from '../error/syntaxError.mjs';\nimport { Token } from './ast.mjs';\nimport { isNameStart } from './characterClasses.mjs';\nimport { createToken, printCodePointAt, readName } from './lexer.mjs';\nimport { TokenKind } from './tokenKind.mjs';\n/**\n * Given a Source schema coordinate, creates a Lexer for that source.\n * A SchemaCoordinateLexer is a stateful stream generator in that every time\n * it is advanced, it returns the next token in the Source. Assuming the\n * source lexes, the final Token emitted by the lexer will be of kind\n * EOF, after which the lexer will repeatedly return the same EOF token\n * whenever called.\n */\n\nexport class SchemaCoordinateLexer {\n  /**\n   * The previously focused non-ignored token.\n   */\n\n  /**\n   * The currently focused non-ignored token.\n   */\n\n  /**\n   * The (1-indexed) line containing the current token.\n   * Since a schema coordinate may not contain newline, this value is always 1.\n   */\n  line = 1;\n  /**\n   * The character offset at which the current line begins.\n   * Since a schema coordinate may not contain newline, this value is always 0.\n   */\n\n  lineStart = 0;\n\n  constructor(source) {\n    const startOfFileToken = new Token(TokenKind.SOF, 0, 0, 0, 0);\n    this.source = source;\n    this.lastToken = startOfFileToken;\n    this.token = startOfFileToken;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'SchemaCoordinateLexer';\n  }\n  /**\n   * Advances the token stream to the next non-ignored token.\n   */\n\n  advance() {\n    this.lastToken = this.token;\n    const token = (this.token = this.lookahead());\n    return token;\n  }\n  /**\n   * Looks ahead and returns the next non-ignored token, but does not change\n   * the current Lexer token.\n   */\n\n  lookahead() {\n    let token = this.token;\n\n    if (token.kind !== TokenKind.EOF) {\n      // Read the next token and form a link in the token linked-list.\n      const nextToken = readNextToken(this, token.end); // @ts-expect-error next is only mutable during parsing.\n\n      token.next = nextToken; // @ts-expect-error prev is only mutable during parsing.\n\n      nextToken.prev = token;\n      token = nextToken;\n    }\n\n    return token;\n  }\n}\n/**\n * Gets the next token from the source starting at the given position.\n */\n\nfunction readNextToken(lexer, start) {\n  const body = lexer.source.body;\n  const bodyLength = body.length;\n  const position = start;\n\n  if (position < bodyLength) {\n    const code = body.charCodeAt(position);\n\n    switch (code) {\n      case 0x002e:\n        // .\n        return createToken(lexer, TokenKind.DOT, position, position + 1);\n\n      case 0x0028:\n        // (\n        return createToken(lexer, TokenKind.PAREN_L, position, position + 1);\n\n      case 0x0029:\n        // )\n        return createToken(lexer, TokenKind.PAREN_R, position, position + 1);\n\n      case 0x003a:\n        // :\n        return createToken(lexer, TokenKind.COLON, position, position + 1);\n\n      case 0x0040:\n        // @\n        return createToken(lexer, TokenKind.AT, position, position + 1);\n    } // Name\n\n    if (isNameStart(code)) {\n      return readName(lexer, position);\n    }\n\n    throw syntaxError(\n      lexer.source,\n      position,\n      `Invalid character: ${printCodePointAt(lexer, position)}.`,\n    );\n  }\n\n  return createToken(lexer, TokenKind.EOF, bodyLength, bodyLength);\n}\n"],"mappings":"AAAA,SAASA,WAAW,QAAQ,0BAA0B;AACtD,SAASC,KAAK,QAAQ,WAAW;AACjC,SAASC,WAAW,QAAQ,wBAAwB;AACpD,SAASC,WAAW,EAAEC,gBAAgB,EAAEC,QAAQ,QAAQ,aAAa;AACrE,SAASC,SAAS,QAAQ,iBAAiB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,MAAMC,qBAAqB,CAAC;EACjC;AACF;AACA;;EAEE;AACF;AACA;;EAEE;AACF;AACA;AACA;EACEC,IAAI,GAAG,CAAC;EACR;AACF;AACA;AACA;;EAEEC,SAAS,GAAG,CAAC;EAEbC,WAAWA,CAACC,MAAM,EAAE;IAClB,MAAMC,gBAAgB,GAAG,IAAIX,KAAK,CAACK,SAAS,CAACO,GAAG,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;IAC7D,IAAI,CAACF,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACG,SAAS,GAAGF,gBAAgB;IACjC,IAAI,CAACG,KAAK,GAAGH,gBAAgB;EAC/B;EAEA,KAAKI,MAAM,CAACC,WAAW,IAAI;IACzB,OAAO,uBAAuB;EAChC;EACA;AACF;AACA;;EAEEC,OAAOA,CAAA,EAAG;IACR,IAAI,CAACJ,SAAS,GAAG,IAAI,CAACC,KAAK;IAC3B,MAAMA,KAAK,GAAI,IAAI,CAACA,KAAK,GAAG,IAAI,CAACI,SAAS,CAAC,CAAE;IAC7C,OAAOJ,KAAK;EACd;EACA;AACF;AACA;AACA;;EAEEI,SAASA,CAAA,EAAG;IACV,IAAIJ,KAAK,GAAG,IAAI,CAACA,KAAK;IAEtB,IAAIA,KAAK,CAACK,IAAI,KAAKd,SAAS,CAACe,GAAG,EAAE;MAChC;MACA,MAAMC,SAAS,GAAGC,aAAa,CAAC,IAAI,EAAER,KAAK,CAACS,GAAG,CAAC,CAAC,CAAC;;MAElDT,KAAK,CAACU,IAAI,GAAGH,SAAS,CAAC,CAAC;;MAExBA,SAAS,CAACI,IAAI,GAAGX,KAAK;MACtBA,KAAK,GAAGO,SAAS;IACnB;IAEA,OAAOP,KAAK;EACd;AACF;AACA;AACA;AACA;;AAEA,SAASQ,aAAaA,CAACI,KAAK,EAAEC,KAAK,EAAE;EACnC,MAAMC,IAAI,GAAGF,KAAK,CAAChB,MAAM,CAACkB,IAAI;EAC9B,MAAMC,UAAU,GAAGD,IAAI,CAACE,MAAM;EAC9B,MAAMC,QAAQ,GAAGJ,KAAK;EAEtB,IAAII,QAAQ,GAAGF,UAAU,EAAE;IACzB,MAAMG,IAAI,GAAGJ,IAAI,CAACK,UAAU,CAACF,QAAQ,CAAC;IAEtC,QAAQC,IAAI;MACV,KAAK,MAAM;QACT;QACA,OAAO9B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAAC6B,GAAG,EAAEH,QAAQ,EAAEA,QAAQ,GAAG,CAAC,CAAC;MAElE,KAAK,MAAM;QACT;QACA,OAAO7B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAAC8B,OAAO,EAAEJ,QAAQ,EAAEA,QAAQ,GAAG,CAAC,CAAC;MAEtE,KAAK,MAAM;QACT;QACA,OAAO7B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAAC+B,OAAO,EAAEL,QAAQ,EAAEA,QAAQ,GAAG,CAAC,CAAC;MAEtE,KAAK,MAAM;QACT;QACA,OAAO7B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAACgC,KAAK,EAAEN,QAAQ,EAAEA,QAAQ,GAAG,CAAC,CAAC;MAEpE,KAAK,MAAM;QACT;QACA,OAAO7B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAACiC,EAAE,EAAEP,QAAQ,EAAEA,QAAQ,GAAG,CAAC,CAAC;IACnE,CAAC,CAAC;;IAEF,IAAI9B,WAAW,CAAC+B,IAAI,CAAC,EAAE;MACrB,OAAO5B,QAAQ,CAACsB,KAAK,EAAEK,QAAQ,CAAC;IAClC;IAEA,MAAMhC,WAAW,CACf2B,KAAK,CAAChB,MAAM,EACZqB,QAAQ,EACR,sBAAsB5B,gBAAgB,CAACuB,KAAK,EAAEK,QAAQ,CAAC,GACzD,CAAC;EACH;EAEA,OAAO7B,WAAW,CAACwB,KAAK,EAAErB,SAAS,CAACe,GAAG,EAAES,UAAU,EAAEA,UAAU,CAAC;AAClE","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}